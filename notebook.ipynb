{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664c1587",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "In this section, we configure the repository paths and load the datasets (query dataset and document corpus). We use the Hugging Face datasets library. If the data is already downloaded, it is loaded from the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8213c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'spanish-ir/'\n",
    "d = { 'dataset': 'messirve', 'corpus': 'eswiki_20240401_corpus' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f18ece43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import datasets\n",
    "\n",
    "dataset, corpus = None, None\n",
    "\n",
    "if not os.path.isdir('dataset'):\n",
    "    revision = '1.2'\n",
    "    country = 'full'\n",
    "    dataset = datasets.load_dataset(repo + d['dataset'],\n",
    "        revision=revision, country=country)\n",
    "\n",
    "if not os.path.isdir('corpus'):\n",
    "    corpus = datasets.load_dataset(repo + d['corpus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4512eeb4",
   "metadata": {},
   "source": [
    "If the dataset and corpus were not downloaded in the previous step (because they already existed), we load them from the local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91e3675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we already have the dataset, load them from disk\n",
    "dataset = dataset if dataset is not None else datasets.load_from_disk('dataset')\n",
    "train, test = dataset['train'].to_pandas(), dataset['test'].to_pandas()\n",
    "\n",
    "corpus = corpus if corpus is not None else datasets.load_from_disk('corpus')\n",
    "corpus = corpus['corpus'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d7825",
   "metadata": {},
   "source": [
    "Once we have the test and train sets and the corpus, we can check their structure, especially the columns and their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367a6d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 766296 entries, 0 to 766295\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               766296 non-null  int64  \n",
      " 1   query            766296 non-null  str    \n",
      " 2   docid            766296 non-null  str    \n",
      " 3   docid_text       766296 non-null  str    \n",
      " 4   docid_title      766296 non-null  str    \n",
      " 5   query_date       766296 non-null  object \n",
      " 6   answer_date      766296 non-null  object \n",
      " 7   match_score      766296 non-null  float32\n",
      " 8   expanded_search  766296 non-null  bool   \n",
      " 9   answer_type      766296 non-null  str    \n",
      " 10  id_country       766296 non-null  float64\n",
      "dtypes: bool(1), float32(1), float64(1), int64(1), object(2), str(5)\n",
      "memory usage: 463.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5432a222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>docid</th>\n",
       "      <th>docid_text</th>\n",
       "      <th>docid_title</th>\n",
       "      <th>query_date</th>\n",
       "      <th>answer_date</th>\n",
       "      <th>match_score</th>\n",
       "      <th>expanded_search</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>id_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7397857</td>\n",
       "      <td>cuántos inning se juegan en el kickingball</td>\n",
       "      <td>1869086#17</td>\n",
       "      <td>El juego de kitball tiene 6 entradas y cada un...</td>\n",
       "      <td>Kickball</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>0.8829</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>976827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7397858</td>\n",
       "      <td>cómo beneficia la biodiversidad a la salud de...</td>\n",
       "      <td>16208#36</td>\n",
       "      <td>La biodiversidad es importante ya que cada esp...</td>\n",
       "      <td>Biodiversidad</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>976828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7397861</td>\n",
       "      <td>quienes somos</td>\n",
       "      <td>3328953#1</td>\n",
       "      <td>Wikipedia es una enciclopedia libre, políglota...</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>6328791.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              query       docid  \\\n",
       "0  7397857         cuántos inning se juegan en el kickingball  1869086#17   \n",
       "1  7397858   cómo beneficia la biodiversidad a la salud de...    16208#36   \n",
       "2  7397861                                      quienes somos   3328953#1   \n",
       "\n",
       "                                          docid_text    docid_title  \\\n",
       "0  El juego de kitball tiene 6 entradas y cada un...       Kickball   \n",
       "1  La biodiversidad es importante ya que cada esp...  Biodiversidad   \n",
       "2  Wikipedia es una enciclopedia libre, políglota...      Wikipedia   \n",
       "\n",
       "   query_date answer_date  match_score  expanded_search answer_type  \\\n",
       "0  2024-04-07  2024-05-06       0.8829            False   feat_snip   \n",
       "1  2024-04-06  2024-05-09       1.0000            False   feat_snip   \n",
       "2  2024-05-18  2024-06-24       1.0000            False   feat_snip   \n",
       "\n",
       "   id_country  \n",
       "0    976827.0  \n",
       "1    976828.0  \n",
       "2   6328791.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef90a92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 174078 entries, 0 to 174077\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               174078 non-null  int64  \n",
      " 1   query            174078 non-null  str    \n",
      " 2   docid            174078 non-null  str    \n",
      " 3   docid_text       174078 non-null  str    \n",
      " 4   docid_title      174078 non-null  str    \n",
      " 5   query_date       174078 non-null  object \n",
      " 6   answer_date      174078 non-null  object \n",
      " 7   match_score      174078 non-null  float32\n",
      " 8   expanded_search  174078 non-null  bool   \n",
      " 9   answer_type      174078 non-null  str    \n",
      " 10  id_country       174078 non-null  float64\n",
      "dtypes: bool(1), float32(1), float64(1), int64(1), object(2), str(5)\n",
      "memory usage: 105.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae758b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>docid</th>\n",
       "      <th>docid_text</th>\n",
       "      <th>docid_title</th>\n",
       "      <th>query_date</th>\n",
       "      <th>answer_date</th>\n",
       "      <th>match_score</th>\n",
       "      <th>expanded_search</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>id_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7397859</td>\n",
       "      <td>en grecia quién aplico la democracia radical</td>\n",
       "      <td>87525#2</td>\n",
       "      <td>Efialtes es considerado por muchos historiador...</td>\n",
       "      <td>Efialtes de Atenas</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>976830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7397860</td>\n",
       "      <td>que conoces de la familia arduino</td>\n",
       "      <td>1337914#0</td>\n",
       "      <td>Arduino es una compañía de desarrollo de \"soft...</td>\n",
       "      <td>Arduino</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>5870869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7397866</td>\n",
       "      <td>1 arroba cuantas kilogramos tiene</td>\n",
       "      <td>77666#7</td>\n",
       "      <td>En Bolivia y Perú hojas de coca se comercializ...</td>\n",
       "      <td>Arroba (unidad de masa)</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>976874.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          query      docid  \\\n",
       "0  7397859   en grecia quién aplico la democracia radical    87525#2   \n",
       "1  7397860              que conoces de la familia arduino  1337914#0   \n",
       "2  7397866              1 arroba cuantas kilogramos tiene    77666#7   \n",
       "\n",
       "                                          docid_text              docid_title  \\\n",
       "0  Efialtes es considerado por muchos historiador...       Efialtes de Atenas   \n",
       "1  Arduino es una compañía de desarrollo de \"soft...                  Arduino   \n",
       "2  En Bolivia y Perú hojas de coca se comercializ...  Arroba (unidad de masa)   \n",
       "\n",
       "   query_date answer_date  match_score  expanded_search answer_type  \\\n",
       "0  2024-04-07  2024-05-06          1.0            False   feat_snip   \n",
       "1  2024-05-20  2024-06-20          1.0            False   feat_snip   \n",
       "2  2024-04-09  2024-05-07          1.0            False   feat_snip   \n",
       "\n",
       "   id_country  \n",
       "0    976830.0  \n",
       "1   5870869.0  \n",
       "2    976874.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e0adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 14047759 entries, 0 to 14047758\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   docid   str  \n",
      " 1   title   str  \n",
      " 2   text    str  \n",
      "dtypes: str(3)\n",
      "memory usage: 5.3 GB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f15cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7#0</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Para otros usos de este término, véase Andorra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7#1</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra, oficialmente Principado de Andorra ()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7#2</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Con sus 468 km² de extensión territorial, Ando...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docid    title                                               text\n",
       "0   7#0  Andorra  Para otros usos de este término, véase Andorra...\n",
       "1   7#1  Andorra  Andorra, oficialmente Principado de Andorra ()...\n",
       "2   7#2  Andorra  Con sus 468 km² de extensión territorial, Ando..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347a136",
   "metadata": {},
   "source": [
    "### Initial Filtering and Cleaning\n",
    "\n",
    "To optimize memory usage, we remove columns from the dataset that are not required for the search (dates, metadata, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id', 'docid_text', 'query_date', 'answer_date', 'expanded_search', 'answer_type', 'id_country']\n",
    "train.drop(columns=columns, inplace=True)\n",
    "test.drop(columns=columns,  inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd37b47",
   "metadata": {},
   "source": [
    "Next, the corpus is filtered to retain only the documents that appear in the training or test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bb93020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# select only the documents that are present in the dataset\n",
    "docids = set(train['docid']) | set(test['docid'])\n",
    "subcorpus = corpus[corpus['docid'].isin(docids)].copy()\n",
    "\n",
    "# free memory\n",
    "del corpus\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cb9fa",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We define two preprocessing strategies depending on the retrieval method to be used:\n",
    "\n",
    "- For ``TF-IDF``: A heavy cleaning will be applied, including stopword removal and normalization to reduce noise.\n",
    "\n",
    "- For ``Embeddings``: A light cleaning will be performed, involving only lowercasing and punctuation removal, as semantic models require the context provided by functional words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed5f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stops = set(stopwords.words('spanish'))\n",
    "\n",
    "def preprocess_tfidf(text: str) -> str:\n",
    "    \"\"\" Applies strong preprocessing to a text \"\"\"\n",
    "    text = text.lower()\n",
    "    # remove punctuation signs\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remove stopwords\n",
    "    words = [w for w in text.split() if w not in stops]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def preprocess_embeddings(text: str) -> str:\n",
    "    \"\"\" Applies light preprocessing to a text \"\"\"\n",
    "    text = text.lower()\n",
    "    # remove punctuation signs\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f7d44d",
   "metadata": {},
   "source": [
    "Now, we use joblib to parallelize the text processing and speed up the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67676a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def parallel_apply(series, f):\n",
    "    # applies a function to a pandas series in parallel\n",
    "    return Parallel(n_jobs=-1)(delayed(f)(x) for x in series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07640df",
   "metadata": {},
   "source": [
    "Once the parallelization function is defined, we preprocess the required columns from both the test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c270299",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['query', 'docid_title']:\n",
    "    # apply the preprocessing to the dataset columns, for embeddings\n",
    "    train[column + '_raw'] = parallel_apply(train[column], preprocess_embeddings)\n",
    "    test[column + '_raw'] = parallel_apply(test[column], preprocess_embeddings)\n",
    "\n",
    "    # apply the preprocessing to the dataset columns, for tf-idf\n",
    "    train[column + '_tfidf'] = parallel_apply(train[column], preprocess_tfidf)\n",
    "    test[column + '_tfidf'] = parallel_apply(test[column], preprocess_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd762a4f",
   "metadata": {},
   "source": [
    "In the same way, the corpus is processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59b3f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['text', 'title']:\n",
    "    # apply the preprocessing to the corpus columns for embeddings & tf-idf\n",
    "    subcorpus[column + '_raw'] = parallel_apply(subcorpus[column], preprocess_embeddings)\n",
    "    subcorpus[column + '_tfidf'] = parallel_apply(subcorpus[column], preprocess_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f67ac",
   "metadata": {},
   "source": [
    "### TF-IDF Retrieval\n",
    "\n",
    "In this section, we will use the classic Bag of Words approach. To do this, we first vectorize the corpus and the queries, and then calculate the cosine similarity between each query and the documents.\n",
    "\n",
    "### Vectorization of Documents and Queries\n",
    "\n",
    "We configure the TfidfVectorizer to work with unigrams and bigrams, and we limit the vocabulary to 50,000 features to keep memory management viable.\n",
    "\n",
    "In cases where more computational power is available, using higher-dimensional n-grams (e.g., trigrams) can help better capture textual relationships, at the cost of increased computation and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da172db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    sublinear_tf=True, \n",
    "    max_features=50_000,\n",
    "    norm='l2',\n",
    "    max_df=0.85,\n",
    "    min_df=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b7c91",
   "metadata": {},
   "source": [
    "When vectorizing, we chose to combine the title and the text of the corpus to capture as much information as possible, since the title often serves as a summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_combined = subcorpus['title_tfidf'].fillna('') + ' ' + subcorpus['text_tfidf']\n",
    "corpus_tfidf = vectorizer.fit_transform(corpus_combined).tocsc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fadd97b",
   "metadata": {},
   "source": [
    "On the other hand, the train and test queries are combined to obtain all queries and vectorize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pandas.concat([train['query_tfidf'], test['query_tfidf']])\n",
    "queries_tfidf = vectorizer.transform(queries).tocsc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5d050",
   "metadata": {},
   "source": [
    "### Similarity Calculation and Ranking\n",
    "\n",
    "Next, we define a function to calculate cosine similarity in batches of queries to avoid RAM allocation errors when working with very large matrices. That said, we use argpartition to efficiently find the top-k elements within each batch, sorted by score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80dfc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def rank_batch(query_matrix, corpus_tfidf, top_k=100):\n",
    "    \"\"\" Gets the top k most similar documents for each query \"\"\"\n",
    "    # obtain similarity (query - corpus)\n",
    "    scores = cosine_similarity(\n",
    "        query_matrix, \n",
    "        corpus_tfidf,\n",
    "        dense_output=False)\n",
    "    results = []\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        # for each query, get the top k results\n",
    "        # get the top k indices, sorted by score\n",
    "        row = scores[i]\n",
    "        k = min(top_k, row.nnz)\n",
    "        top_idx = np.argpartition(row.data, -k)[-k:]\n",
    "        doc_idx = row.indices[top_idx]\n",
    "        doc_scores = row.data[top_idx]\n",
    "        order = np.argsort(-doc_scores)\n",
    "        results.append(doc_idx[order])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba51f4a",
   "metadata": {},
   "source": [
    "Once this function is defined, if a file with the already calculated rankings does not exist, they are computed and saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('rankings_tfidf.npy'):\n",
    "    batch_size = 256\n",
    "    rankings_tfidf = []\n",
    "    top_k = 100\n",
    "\n",
    "    # rank the queries using tf-idf & save the results to disk\n",
    "    for i in range(0, queries_tfidf.shape[0], batch_size):\n",
    "        batch = queries_tfidf[i:i+batch_size]\n",
    "        batch_rankings = rank_batch(batch, corpus_tfidf, top_k=top_k)\n",
    "        rankings_tfidf.extend(batch_rankings)\n",
    "\n",
    "    # save the ranking to a file\n",
    "    normalized_ranking = []\n",
    "    for ranking in rankings_tfidf:\n",
    "        if ranking.shape[0] < top_k:\n",
    "            # add padding to the ranking if len < 100\n",
    "            ranking = np.pad(ranking, (0, top_k - ranking.shape[0]),\n",
    "                constant_values=-1)\n",
    "        normalized_ranking.append(ranking)\n",
    "    np.save('rankings_tfidf.npy', np.array(normalized_ranking))\n",
    "else:\n",
    "    # load the tf-idf rankings from disk\n",
    "    rankings_tfidf = np.load('rankings_tfidf.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b09925",
   "metadata": {},
   "source": [
    "### Retrieval with Embeddings\n",
    "\n",
    "Now, we use a semantic model (sentence-transformers) to convert texts into dense vectors. This method typically captures semantic meaning more effectively because, unlike models such as TF-IDF that focus on exact word matching, these can capture similarities between different words that share the same meaning.\n",
    "\n",
    "#### Preparation\n",
    "\n",
    "First of all, we combine the title and text of the corpus (just as in the previous section), but in this case, using the preprocessing specifically designed for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "156548f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_combined_emb = subcorpus['title_raw'].fillna('') + ' ' + subcorpus['text_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c86b66",
   "metadata": {},
   "source": [
    "Now we must load the model that will be responsible for calculating the embeddings. Specifically, we will use [sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2). This model maps sentences and paragraphs to a 384 dimensional dense vector space.\n",
    "\n",
    "It is true that a language-specific model for Spanish could have been used, such as [hiiamsid/sentence_similarity_spanish_es](https://huggingface.co/hiiamsid/sentence_similarity_spanish_es), or a multilingual one with more dimensions like [sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2). However, my machine's computing capacity is standard, and such models could take several hours to process. Furthermore, this is an experimental project rather than a production-ready one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "942903f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 1271.54it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa21b60",
   "metadata": {},
   "source": [
    "#### Corpus Encoding\n",
    "\n",
    "Once the model is loaded, we generate the embeddings for all documents in the corpus. If the file containing the encoded corpus already exists, it will be loaded instead of repeating the process, which can be time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6d018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2943/2943 [1:02:35<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('corpus_embeddings.npy'):\n",
    "    # encode the corpus using the sentence transformer model, then save to disk\n",
    "    corpus_embeddings = model.encode(corpus_combined_emb.tolist(), batch_size=64, \n",
    "        show_progress_bar=True, normalize_embeddings=True)\n",
    "    np.save('corpus_embeddings.npy', corpus_embeddings)\n",
    "else:\n",
    "    # load the corpus embeddings from disk\n",
    "    corpus_embeddings = np.load('corpus_embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c104f6",
   "metadata": {},
   "source": [
    "#### Query Encoding\n",
    "\n",
    "Now, we generate the embeddings for all queries (both train and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4ba9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = pandas.concat([train['query_raw'], test['query_raw']]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb5df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 14694/14694 [32:43<00:00,  7.48it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('query_embeddings.npy'):\n",
    "    # encode the queries using the sentence transformer model\n",
    "    query_embeddings = model.encode(all_queries, batch_size=64, \n",
    "        show_progress_bar=True, normalize_embeddings=True)\n",
    "    np.save('query_embeddings.npy', query_embeddings)\n",
    "else:\n",
    "    # load the query embeddings from disk\n",
    "    query_embeddings = np.load('query_embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c17999",
   "metadata": {},
   "source": [
    "#### Ranking with Embeddings\n",
    "\n",
    "Since the vectors are normalized, cosine similarity is equivalent to the dot product. This allows us to calculate similarities between queries and the corpus very quickly through matrix multiplication, again using batches instead of processing all the data at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aec0372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_batch_embeddings(query_emb, corpus_emb, top_k=100):\n",
    "    \"\"\" Gets the top k most similar documents for each query using embeddings \"\"\"\n",
    "    scores = query_emb @ corpus_emb.T\n",
    "    rankings = []\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        # for each query, get the top k results\n",
    "        # get the top k indices, sorted by score\n",
    "        row = scores[i]\n",
    "        part_idx = np.argpartition(row, -top_k)[-top_k:]\n",
    "        top_scores = row[part_idx]\n",
    "        sorted_order = np.argsort(-top_scores)\n",
    "        top_k_idx = part_idx[sorted_order]\n",
    "        rankings.append(top_k_idx)\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac9e9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('embedding_rankings.npy'):\n",
    "    batch_size = 256\n",
    "    embedding_rankings = []\n",
    "\n",
    "    # rank the queries using embeddings & save the results to disk\n",
    "    for i in range(0, query_embeddings.shape[0], batch_size):\n",
    "        batch = query_embeddings[i:i+batch_size]\n",
    "        batch_rankings = rank_batch_embeddings(batch, corpus_embeddings)\n",
    "        embedding_rankings.extend(batch_rankings)\n",
    "    np.save('embedding_rankings.npy', np.array(embedding_rankings))\n",
    "else:\n",
    "    # load the embedding rankings from disk\n",
    "    embedding_rankings = np.load('embedding_rankings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe6031",
   "metadata": {},
   "source": [
    "#### Mapping Indices to IDs\n",
    "\n",
    "The current rankings contain numerical indices (positions in the subcorpus array). We need to convert them into the actual ``docid`` values to evaluate them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97ed2c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_docid = subcorpus['docid'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f124fd",
   "metadata": {},
   "source": [
    "We convert both TF-IDF and embedding rankings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f820ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_tdidf_final = []\n",
    "for query_ranking in rankings_tfidf:\n",
    "    top_docids = [idx_to_docid[idx] for idx in query_ranking]\n",
    "    rankings_tdidf_final.append(top_docids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8524432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_emb_final = []\n",
    "for query_indices in embedding_rankings:\n",
    "    top_docids = [idx_to_docid[idx] for idx in query_indices]\n",
    "    rankings_emb_final.append(top_docids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370e570",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Finally, we evaluate both systems (TF-IDF and Embeddings) using three standard Information Retrieval metrics: Precision@k, Recall@k, and nDCG@k. To do this, we define the following evaluation function that compares the ground truth document (y_true) with the list of retrieved documents (rankings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb2364c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def evaluate(y_true, rankings, k_values=[1,5,10]):\n",
    "    \"\"\" Evaluates a IR system \"\"\"\n",
    "    metrics_results = {k: {'precision': 0.0, 'recall': 0.0, 'ndcg': 0.0} for k in k_values}\n",
    "    n_queries = len(y_true)\n",
    "\n",
    "    for true_doc_id, predicted_docs in zip(y_true, rankings):\n",
    "        # find the idx of the correct document in the list\n",
    "        rank_dict = { doc: idx + 1 for idx, doc \n",
    "            in enumerate(predicted_docs) }\n",
    "        rank = rank_dict.get(true_doc_id, float('inf'))\n",
    "\n",
    "        for k in k_values:\n",
    "            if rank <= k:\n",
    "                k_metric = metrics_results[k]\n",
    "                k_metric['precision'] += 1.0 / k\n",
    "                k_metric['recall'] += 1.0\n",
    "                k_metric['ndcg'] += 1.0 / math.log2(rank + 1)\n",
    "\n",
    "    final_metrics = {}\n",
    "    for k in k_values:\n",
    "        k_metric = metrics_results[k]\n",
    "        final_metrics[f'Precision@{k}'] = k_metric['precision'] / n_queries\n",
    "        final_metrics[f'Recall@{k}'] = k_metric['recall'] / n_queries\n",
    "        final_metrics[f'nDCG@{k}'] = k_metric['ndcg'] / n_queries\n",
    "    return pandas.DataFrame([final_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b76563",
   "metadata": {},
   "source": [
    "Once the function is defined, we prepare the test data (ground truth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa903112",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test['docid'].tolist()\n",
    "n_train = len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751db1b",
   "metadata": {},
   "source": [
    "First, we evaluate TF-IDF, using only the portion of the rankings that corresponds to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4d64cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@1</th>\n",
       "      <th>Recall@1</th>\n",
       "      <th>nDCG@1</th>\n",
       "      <th>Precision@5</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100168</td>\n",
       "      <td>0.100168</td>\n",
       "      <td>0.100168</td>\n",
       "      <td>0.051695</td>\n",
       "      <td>0.258476</td>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.034316</td>\n",
       "      <td>0.343157</td>\n",
       "      <td>0.209103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision@1  Recall@1    nDCG@1  Precision@5  Recall@5    nDCG@5  \\\n",
       "0     0.100168  0.100168  0.100168     0.051695  0.258476  0.181666   \n",
       "\n",
       "   Precision@10  Recall@10   nDCG@10  \n",
       "0      0.034316   0.343157  0.209103  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings_tfidf_test = rankings_tdidf_final[n_train:]\n",
    "evaluate(y_true, rankings_tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395edf7b",
   "metadata": {},
   "source": [
    "In the same way, the embeddings are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7cadbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@1</th>\n",
       "      <th>Recall@1</th>\n",
       "      <th>nDCG@1</th>\n",
       "      <th>Precision@5</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174945</td>\n",
       "      <td>0.174945</td>\n",
       "      <td>0.174945</td>\n",
       "      <td>0.069731</td>\n",
       "      <td>0.348654</td>\n",
       "      <td>0.266843</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>0.418628</td>\n",
       "      <td>0.289532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision@1  Recall@1    nDCG@1  Precision@5  Recall@5    nDCG@5  \\\n",
       "0     0.174945  0.174945  0.174945     0.069731  0.348654  0.266843   \n",
       "\n",
       "   Precision@10  Recall@10   nDCG@10  \n",
       "0      0.041863   0.418628  0.289532  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings_emb_test = rankings_emb_final[n_train:]\n",
    "evaluate(y_true, rankings_emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2fba02",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "In this work, an information retrieval system in Spanish has been implemented and evaluated using the Messirve dataset and a subset of Wikipedia. Two approaches were compared: a lexical model based on TF-IDF and a semantic model based on embeddings.\n",
    "\n",
    "The results obtained show a clear superiority of the embedding-based model over the TF-IDF approach across all evaluated metrics. Specifically, Precision@1 increases from 0.100 with TF-IDF to 0.175 with embeddings, representing a significant improvement in the proportion of queries where the correct document appears in the top position. Likewise, Recall@10 rises from 0.343 to 0.419, indicating that the semantic model retrieves the relevant document within the top 10 in a greater number of cases. Consistently, nDCG@10 also improves from 0.209 to 0.290, reflecting a better ranking of the results.\n",
    "\n",
    "These findings confirm that the embedding model captures semantic similarity between queries and documents more effectively than the lexical model based on term matching. While TF-IDF relies on exact word matches, embeddings allow for generalization across synonyms and variations, providing much greater flexibility.\n",
    "\n",
    "As potential future improvements, we propose exploring hybrid approaches that combine sparse and dense models, using more advanced embedding models, applying re-ranking techniques with cross-encoders, or employing more complex and language-specific models for Spanish, as previously discussed in this notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
