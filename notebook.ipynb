{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664c1587",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "\n",
    "En esta sección configuramos las rutas de los repositorios y cargamos los conjuntos de datos (dataset de consultas y corpus de documentos).  Utilizamos la librería datasets de Hugging Face. Si los datos ya están descargados en disco, se cargan desde el disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8213c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'spanish-ir/'\n",
    "d = { 'dataset': 'messirve', 'corpus': 'eswiki_20240401_corpus' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f18ece43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import datasets\n",
    "\n",
    "dataset, corpus = None, None\n",
    "\n",
    "if not os.path.isdir('dataset'):\n",
    "    revision = '1.2'\n",
    "    country = 'full'\n",
    "    dataset = datasets.load_dataset(repo + d['dataset'],\n",
    "        revision=revision, country=country)\n",
    "\n",
    "if not os.path.isdir('corpus'):\n",
    "    corpus = datasets.load_dataset(repo + d['corpus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4512eeb4",
   "metadata": {},
   "source": [
    "Si los objetos no se descargaron en el paso anterior (porque ya existían), los cargamos desde el disco local. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91e3675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case we already have the dataset, load them from disk\n",
    "dataset = dataset if dataset is not None else datasets.load_from_disk('dataset')\n",
    "train, test = dataset['train'].to_pandas(), dataset['test'].to_pandas()\n",
    "\n",
    "corpus = corpus if corpus is not None else datasets.load_from_disk('corpus')\n",
    "corpus = corpus['corpus'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d7825",
   "metadata": {},
   "source": [
    "Una vez tenemos los conjuntos de test, train y el corpus, podemos comprobar su estructura, en especial las columnas y su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367a6d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 766296 entries, 0 to 766295\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               766296 non-null  int64  \n",
      " 1   query            766296 non-null  str    \n",
      " 2   docid            766296 non-null  str    \n",
      " 3   docid_text       766296 non-null  str    \n",
      " 4   docid_title      766296 non-null  str    \n",
      " 5   query_date       766296 non-null  object \n",
      " 6   answer_date      766296 non-null  object \n",
      " 7   match_score      766296 non-null  float32\n",
      " 8   expanded_search  766296 non-null  bool   \n",
      " 9   answer_type      766296 non-null  str    \n",
      " 10  id_country       766296 non-null  float64\n",
      "dtypes: bool(1), float32(1), float64(1), int64(1), object(2), str(5)\n",
      "memory usage: 463.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5432a222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>docid</th>\n",
       "      <th>docid_text</th>\n",
       "      <th>docid_title</th>\n",
       "      <th>query_date</th>\n",
       "      <th>answer_date</th>\n",
       "      <th>match_score</th>\n",
       "      <th>expanded_search</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>id_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7397857</td>\n",
       "      <td>cuántos inning se juegan en el kickingball</td>\n",
       "      <td>1869086#17</td>\n",
       "      <td>El juego de kitball tiene 6 entradas y cada un...</td>\n",
       "      <td>Kickball</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>0.8829</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>976827.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7397858</td>\n",
       "      <td>cómo beneficia la biodiversidad a la salud de...</td>\n",
       "      <td>16208#36</td>\n",
       "      <td>La biodiversidad es importante ya que cada esp...</td>\n",
       "      <td>Biodiversidad</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>976828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7397861</td>\n",
       "      <td>quienes somos</td>\n",
       "      <td>3328953#1</td>\n",
       "      <td>Wikipedia es una enciclopedia libre, políglota...</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>2024-05-18</td>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>6328791.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              query       docid  \\\n",
       "0  7397857         cuántos inning se juegan en el kickingball  1869086#17   \n",
       "1  7397858   cómo beneficia la biodiversidad a la salud de...    16208#36   \n",
       "2  7397861                                      quienes somos   3328953#1   \n",
       "\n",
       "                                          docid_text    docid_title  \\\n",
       "0  El juego de kitball tiene 6 entradas y cada un...       Kickball   \n",
       "1  La biodiversidad es importante ya que cada esp...  Biodiversidad   \n",
       "2  Wikipedia es una enciclopedia libre, políglota...      Wikipedia   \n",
       "\n",
       "   query_date answer_date  match_score  expanded_search answer_type  \\\n",
       "0  2024-04-07  2024-05-06       0.8829            False   feat_snip   \n",
       "1  2024-04-06  2024-05-09       1.0000            False   feat_snip   \n",
       "2  2024-05-18  2024-06-24       1.0000            False   feat_snip   \n",
       "\n",
       "   id_country  \n",
       "0    976827.0  \n",
       "1    976828.0  \n",
       "2   6328791.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef90a92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 174078 entries, 0 to 174077\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               174078 non-null  int64  \n",
      " 1   query            174078 non-null  str    \n",
      " 2   docid            174078 non-null  str    \n",
      " 3   docid_text       174078 non-null  str    \n",
      " 4   docid_title      174078 non-null  str    \n",
      " 5   query_date       174078 non-null  object \n",
      " 6   answer_date      174078 non-null  object \n",
      " 7   match_score      174078 non-null  float32\n",
      " 8   expanded_search  174078 non-null  bool   \n",
      " 9   answer_type      174078 non-null  str    \n",
      " 10  id_country       174078 non-null  float64\n",
      "dtypes: bool(1), float32(1), float64(1), int64(1), object(2), str(5)\n",
      "memory usage: 105.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae758b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>docid</th>\n",
       "      <th>docid_text</th>\n",
       "      <th>docid_title</th>\n",
       "      <th>query_date</th>\n",
       "      <th>answer_date</th>\n",
       "      <th>match_score</th>\n",
       "      <th>expanded_search</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>id_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7397859</td>\n",
       "      <td>en grecia quién aplico la democracia radical</td>\n",
       "      <td>87525#2</td>\n",
       "      <td>Efialtes es considerado por muchos historiador...</td>\n",
       "      <td>Efialtes de Atenas</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>976830.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7397860</td>\n",
       "      <td>que conoces de la familia arduino</td>\n",
       "      <td>1337914#0</td>\n",
       "      <td>Arduino es una compañía de desarrollo de \"soft...</td>\n",
       "      <td>Arduino</td>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>5870869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7397866</td>\n",
       "      <td>1 arroba cuantas kilogramos tiene</td>\n",
       "      <td>77666#7</td>\n",
       "      <td>En Bolivia y Perú hojas de coca se comercializ...</td>\n",
       "      <td>Arroba (unidad de masa)</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>feat_snip</td>\n",
       "      <td>976874.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          query      docid  \\\n",
       "0  7397859   en grecia quién aplico la democracia radical    87525#2   \n",
       "1  7397860              que conoces de la familia arduino  1337914#0   \n",
       "2  7397866              1 arroba cuantas kilogramos tiene    77666#7   \n",
       "\n",
       "                                          docid_text              docid_title  \\\n",
       "0  Efialtes es considerado por muchos historiador...       Efialtes de Atenas   \n",
       "1  Arduino es una compañía de desarrollo de \"soft...                  Arduino   \n",
       "2  En Bolivia y Perú hojas de coca se comercializ...  Arroba (unidad de masa)   \n",
       "\n",
       "   query_date answer_date  match_score  expanded_search answer_type  \\\n",
       "0  2024-04-07  2024-05-06          1.0            False   feat_snip   \n",
       "1  2024-05-20  2024-06-20          1.0            False   feat_snip   \n",
       "2  2024-04-09  2024-05-07          1.0            False   feat_snip   \n",
       "\n",
       "   id_country  \n",
       "0    976830.0  \n",
       "1   5870869.0  \n",
       "2    976874.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6e0adc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 14047759 entries, 0 to 14047758\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   docid   str  \n",
      " 1   title   str  \n",
      " 2   text    str  \n",
      "dtypes: str(3)\n",
      "memory usage: 5.3 GB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06f15cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7#0</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Para otros usos de este término, véase Andorra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7#1</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra, oficialmente Principado de Andorra ()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7#2</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Con sus 468 km² de extensión territorial, Ando...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docid    title                                               text\n",
       "0   7#0  Andorra  Para otros usos de este término, véase Andorra...\n",
       "1   7#1  Andorra  Andorra, oficialmente Principado de Andorra ()...\n",
       "2   7#2  Andorra  Con sus 468 km² de extensión territorial, Ando..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347a136",
   "metadata": {},
   "source": [
    "### Filtrado y limpieza inicial\n",
    "\n",
    "Para optimizar el uso de memoria, eliminamos columnas del dataset que no son necesarias para la búsqueda (fechas, metadatos, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id', 'docid_text', 'query_date', 'answer_date', 'expanded_search', 'answer_type', 'id_country']\n",
    "train.drop(columns=columns, inplace=True)\n",
    "test.drop(columns=columns,  inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd37b47",
   "metadata": {},
   "source": [
    "A continuación se filtra el corpus para conservar únicamente los documentos que aparecen en los conjuntos de entrenamiento o prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bb93020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# select only the documents that are present in the dataset\n",
    "docids = set(train['docid']) | set(test['docid'])\n",
    "subcorpus = corpus[corpus['docid'].isin(docids)].copy()\n",
    "\n",
    "# free memory\n",
    "del corpus\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cb9fa",
   "metadata": {},
   "source": [
    "### Preprocesado\n",
    "\n",
    "Definimos dos estrategias de preprocesamiento según el método de recuperación que vayamos a usar: \n",
    "\n",
    "- Para ``TF-IDF``: Se hará uso de una limpieza *fuerte* que incluye eliminación de stopwords y normalización para reducir el ruido.\n",
    "\n",
    "- Para ``Embeddings``: Se hará una limpieza *suave*, donde solo se pasará a minúsculas y eliminarán los signos de puntuación, ya que los modelos semánticos necesitan el contexto de las palabras funcionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed5f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stops = set(stopwords.words('spanish'))\n",
    "\n",
    "def preprocess_tfidf(text: str) -> str:\n",
    "    \"\"\" Applies strong preprocessing to a text \"\"\"\n",
    "    text = text.lower()\n",
    "    # remove punctuation signs\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remove stopwords\n",
    "    words = [w for w in text.split() if w not in stops]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "def preprocess_embeddings(text: str) -> str:\n",
    "    \"\"\" Applies light preprocessing to a text \"\"\"\n",
    "    text = text.lower()\n",
    "    # remove punctuation signs\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b683c5",
   "metadata": {},
   "source": [
    "Ahora, usamos joblib para paraleizar el procesamiento de los textos y acelerar la tarea a la hora de preprocesar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67676a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def parallel_apply(series, f):\n",
    "    # applies a function to a pandas series in parallel\n",
    "    return Parallel(n_jobs=-1)(delayed(f)(x) for x in series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07640df",
   "metadata": {},
   "source": [
    "Una vez definda la función de paralelización, preprocesamos las columnas necesarias del conjunto de test y train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c270299",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['query', 'docid_title']:\n",
    "    # apply the preprocessing to the dataset columns, for embeddings\n",
    "    train[column + '_raw'] = parallel_apply(train[column], preprocess_embeddings)\n",
    "    test[column + '_raw'] = parallel_apply(test[column], preprocess_embeddings)\n",
    "\n",
    "    # apply the preprocessing to the dataset columns, for tf-idf\n",
    "    train[column + '_tfidf'] = parallel_apply(train[column], preprocess_tfidf)\n",
    "    test[column + '_tfidf'] = parallel_apply(test[column], preprocess_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd762a4f",
   "metadata": {},
   "source": [
    "De la misma manera, se procesa el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59b3f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['text', 'title']:\n",
    "    # apply the preprocessing to the corpus columns for embeddings & tf-idf\n",
    "    subcorpus[column + '_raw'] = parallel_apply(subcorpus[column], preprocess_embeddings)\n",
    "    subcorpus[column + '_tfidf'] = parallel_apply(subcorpus[column], preprocess_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c663dcd",
   "metadata": {},
   "source": [
    "### Recuperación con TF-IDF\n",
    "\n",
    "En esta sección se utilizará el enfoque clásico de Bag of Words. Para ello, en primer lugar se vectorizará el corpus y las consultas y después, se calculará la similitud coseno entre cada consulta y los documentos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f67ac",
   "metadata": {},
   "source": [
    "### Vectorizado de documentos y consultas\n",
    "\n",
    "Configuramos el TfidfVectorizer para que trabaje con unigramas y bigramas, y limitamos el vocabulario a 50,000 características para mantener el manejo de memoria viable. \n",
    "\n",
    "En un caso en el que se disponga de mayor capacidad de cómputo, usar ngramas de una mayor dimensionalidad (p.ej. trigramas) puede ayudar a captar mejor las relaciones en los textos, al coste de mayor computo y memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da172db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), \n",
    "    sublinear_tf=True, \n",
    "    max_features=50_000,\n",
    "    norm='l2',\n",
    "    max_df=0.85,\n",
    "    min_df=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b7c91",
   "metadata": {},
   "source": [
    "A la hora de vectorizar, se ha optado por combinar el título y el texto del corpus para intentar capturar la mayor cantidad de información posible ya que el título en muchas ocasiones puede servir de resumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549c943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_combined = subcorpus['title_tfidf'].fillna('') + ' ' + subcorpus['text_tfidf']\n",
    "corpus_tfidf = vectorizer.fit_transform(corpus_combined).tocsc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fadd97b",
   "metadata": {},
   "source": [
    "Por otro lado, se combinan las consultas de train y test para obtener todas las consultas y vectorizarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pandas.concat([train['query_tfidf'], test['query_tfidf']])\n",
    "queries_tfidf = vectorizer.transform(queries).tocsc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5d050",
   "metadata": {},
   "source": [
    "### Cálculo de similitudes y ranking\n",
    "\n",
    "A continuación, definimos una función para calcular la similitud del coseno por grupos (batches) de queries para no provocar RAM allocation errors al trabajar con matrices muy grandes. Dicho esto, utilizamos argpartition para encontrar los top-k elementos de manera eficiente en dicho lote, ordenados por score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80dfc05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def rank_batch(query_matrix, corpus_tfidf, top_k=100):\n",
    "    \"\"\" Gets the top k most similar documents for each query \"\"\"\n",
    "    # obtain similarity (query - corpus)\n",
    "    scores = cosine_similarity(\n",
    "        query_matrix, \n",
    "        corpus_tfidf,\n",
    "        dense_output=False)\n",
    "    results = []\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        # for each query, get the top k results\n",
    "        # get the top k indices, sorted by score\n",
    "        row = scores[i]\n",
    "        k = min(top_k, row.nnz)\n",
    "        top_idx = np.argpartition(row.data, -k)[-k:]\n",
    "        doc_idx = row.indices[top_idx]\n",
    "        doc_scores = row.data[top_idx]\n",
    "        order = np.argsort(-doc_scores)\n",
    "        results.append(doc_idx[order])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba51f4a",
   "metadata": {},
   "source": [
    "Una vez definida esta función, en caso de que no exista un archivo con los rankings ya calculados, estos se calculan y se guardan en disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b0b12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('rankings_tfidf.npy'):\n",
    "    batch_size = 256\n",
    "    rankings_tfidf = []\n",
    "    top_k = 100\n",
    "\n",
    "    # rank the queries using tf-idf & save the results to disk\n",
    "    for i in range(0, queries_tfidf.shape[0], batch_size):\n",
    "        batch = queries_tfidf[i:i+batch_size]\n",
    "        batch_rankings = rank_batch(batch, corpus_tfidf, top_k=top_k)\n",
    "        rankings_tfidf.extend(batch_rankings)\n",
    "\n",
    "    # save the ranking to a file\n",
    "    normalized_ranking = []\n",
    "    for ranking in rankings_tfidf:\n",
    "        if ranking.shape[0] < top_k:\n",
    "            # add padding to the ranking if len < 100\n",
    "            ranking = np.pad(ranking, (0, top_k - ranking.shape[0]),\n",
    "                constant_values=-1)\n",
    "        normalized_ranking.append(ranking)\n",
    "    np.save('rankings_tfidf.npy', np.array(normalized_ranking))\n",
    "else:\n",
    "    # load the tf-idf rankings from disk\n",
    "    rankings_tfidf = np.load('rankings_tfidf.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b09925",
   "metadata": {},
   "source": [
    "### Recuperación con embeddings\n",
    "\n",
    "Ahora utilizamos un modelo semántico (sentence-transformers) para convertir textos en vectores densos. Este método suele capturar mejor el significado semántico, puesto que a diferencia de modelos como TF-IDF que se centran en la coincidencia exacta de palabras, estos pueden llegar a capturar similitudes entre palabras *diferentes* que tengan el mismo significado.\n",
    "\n",
    "#### Preparación\n",
    "\n",
    "Antes de nada, combinamos el título y texto del corpus (igual que se hizo en la sección anterior), pero en este caso con el preprocesado para embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "156548f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_combined_emb = subcorpus['title_raw'].fillna('') + ' ' + subcorpus['text_raw']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c86b66",
   "metadata": {},
   "source": [
    "Ahora hemos de cargar el modelo que se encargará de calcular los embeddings. En concreto se hará uso de [sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2). This model maps sentences and paragraphs to a 384 dimensional dense vector space.\n",
    "\n",
    "Es cierto que que podría haber usado un modelo específico para el idioma espanol, como lo es [hiiamsid/sentence_similarity_spanish_es](https://huggingface.co/hiiamsid/sentence_similarity_spanish_es) o uno multilingue con mas dimensiones como [sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2). Sin embargo, la capacidad de computo de mi maquina es estándar y modelos de este tipo podrían tardar bastantes horas en procesar, además de que esto es un proyecto experimental y no uno de producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "942903f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 1271.54it/s, Materializing param=pooler.dense.weight]                               \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa21b60",
   "metadata": {},
   "source": [
    "#### Codificación del corpus\n",
    "\n",
    "Una vez cargado el modelo, generamos los embeddings de todos los documentos del corpus. Si el archivo con el corpus codificado existe, se cargará en vez de hacer de nuevo este proceso, que puede ser lento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6d018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2943/2943 [1:02:35<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('corpus_embeddings.npy'):\n",
    "    # encode the corpus using the sentence transformer model, then save to disk\n",
    "    corpus_embeddings = model.encode(corpus_combined_emb.tolist(), batch_size=64, \n",
    "        show_progress_bar=True, normalize_embeddings=True)\n",
    "    np.save('corpus_embeddings.npy', corpus_embeddings)\n",
    "else:\n",
    "    # load the corpus embeddings from disk\n",
    "    corpus_embeddings = np.load('corpus_embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c104f6",
   "metadata": {},
   "source": [
    "#### Codificación de consultas\n",
    "\n",
    "Ahora, generamos los embeddings para todas las consultas (train y test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4ba9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_queries = pandas.concat([train['query_raw'], test['query_raw']]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fb5df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 14694/14694 [32:43<00:00,  7.48it/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('query_embeddings.npy'):\n",
    "    # encode the queries using the sentence transformer model\n",
    "    query_embeddings = model.encode(all_queries, batch_size=64, \n",
    "        show_progress_bar=True, normalize_embeddings=True)\n",
    "    np.save('query_embeddings.npy', query_embeddings)\n",
    "else:\n",
    "    # load the query embeddings from disk\n",
    "    query_embeddings = np.load('query_embeddings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c17999",
   "metadata": {},
   "source": [
    "#### Ranking con embeddings\n",
    "\n",
    "Como los vectores están normalizados, la similitud del coseno es equivalente al producto punto (dot product). Esto nos permite calcular similitudes entre queries y corpus muy rápido multiplicando matrices, de nuevo usando batches en vez de todos los datos a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aec0372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_batch_embeddings(query_emb, corpus_emb, top_k=100):\n",
    "    \"\"\" Gets the top k most similar documents for each query using embeddings \"\"\"\n",
    "    scores = query_emb @ corpus_emb.T\n",
    "    rankings = []\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        # for each query, get the top k results\n",
    "        # get the top k indices, sorted by score\n",
    "        row = scores[i]\n",
    "        part_idx = np.argpartition(row, -top_k)[-top_k:]\n",
    "        top_scores = row[part_idx]\n",
    "        sorted_order = np.argsort(-top_scores)\n",
    "        top_k_idx = part_idx[sorted_order]\n",
    "        rankings.append(top_k_idx)\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac9e9cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('embedding_rankings.npy'):\n",
    "    batch_size = 256\n",
    "    embedding_rankings = []\n",
    "\n",
    "    # rank the queries using embeddings & save the results to disk\n",
    "    for i in range(0, query_embeddings.shape[0], batch_size):\n",
    "        batch = query_embeddings[i:i+batch_size]\n",
    "        batch_rankings = rank_batch_embeddings(batch, corpus_embeddings)\n",
    "        embedding_rankings.extend(batch_rankings)\n",
    "    np.save('embedding_rankings.npy', np.array(embedding_rankings))\n",
    "else:\n",
    "    # load the embedding rankings from disk\n",
    "    embedding_rankings = np.load('embedding_rankings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe6031",
   "metadata": {},
   "source": [
    "#### Mapeo de índices a IDs\n",
    "\n",
    "Los rankings actuales contienen índices numéricos (posiciones en el array subcorpus). Necesitamos convertirlos a los ``docid`` reales para poder evaluarlos correctamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97ed2c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_docid = subcorpus['docid'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f124fd",
   "metadata": {},
   "source": [
    "Convertimos rankings de TF-IDF y embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f820ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_tdidf_final = []\n",
    "for query_ranking in rankings_tfidf:\n",
    "    top_docids = [idx_to_docid[idx] for idx in query_ranking]\n",
    "    rankings_tdidf_final.append(top_docids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8524432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings_emb_final = []\n",
    "for query_indices in embedding_rankings:\n",
    "    top_docids = [idx_to_docid[idx] for idx in query_indices]\n",
    "    rankings_emb_final.append(top_docids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370e570",
   "metadata": {},
   "source": [
    "### Evaluación\n",
    "\n",
    "Por último, evaluamos ambos sistemas (TF-IDF y Embeddings) utilizando tres métricas estándar de recuperación de información: Precision@k, Recall@k y nDCG@k. Para ello, se define la siguiente función de evaluación que compara el documento correcto (y_true) con la lista de documentos recuperados (rankings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb2364c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def evaluate(y_true, rankings, k_values=[1,5,10]):\n",
    "    \"\"\" Evaluates a IR system \"\"\"\n",
    "    metrics_results = {k: {'precision': 0.0, 'recall': 0.0, 'ndcg': 0.0} for k in k_values}\n",
    "    n_queries = len(y_true)\n",
    "\n",
    "    for true_doc_id, predicted_docs in zip(y_true, rankings):\n",
    "        # find the idx of the correct document in the list\n",
    "        rank_dict = { doc: idx + 1 for idx, doc \n",
    "            in enumerate(predicted_docs) }\n",
    "        rank = rank_dict.get(true_doc_id, float('inf'))\n",
    "\n",
    "        for k in k_values:\n",
    "            if rank <= k:\n",
    "                k_metric = metrics_results[k]\n",
    "                k_metric['precision'] += 1.0 / k\n",
    "                k_metric['recall'] += 1.0\n",
    "                k_metric['ndcg'] += 1.0 / math.log2(rank + 1)\n",
    "\n",
    "    final_metrics = {}\n",
    "    for k in k_values:\n",
    "        k_metric = metrics_results[k]\n",
    "        final_metrics[f'Precision@{k}'] = k_metric['precision'] / n_queries\n",
    "        final_metrics[f'Recall@{k}'] = k_metric['recall'] / n_queries\n",
    "        final_metrics[f'nDCG@{k}'] = k_metric['ndcg'] / n_queries\n",
    "    return pandas.DataFrame([final_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b76563",
   "metadata": {},
   "source": [
    "Una vez definida la función, preparamos los datos de prueba (ground truth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa903112",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test['docid'].tolist()\n",
    "n_train = len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751db1b",
   "metadata": {},
   "source": [
    "En primer lugar evaluamos TF-IDF, usando solo la parte de los rankings que corresponde al set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4d64cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@1</th>\n",
       "      <th>Recall@1</th>\n",
       "      <th>nDCG@1</th>\n",
       "      <th>Precision@5</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100168</td>\n",
       "      <td>0.100168</td>\n",
       "      <td>0.100168</td>\n",
       "      <td>0.051695</td>\n",
       "      <td>0.258476</td>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.034316</td>\n",
       "      <td>0.343157</td>\n",
       "      <td>0.209103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision@1  Recall@1    nDCG@1  Precision@5  Recall@5    nDCG@5  \\\n",
       "0     0.100168  0.100168  0.100168     0.051695  0.258476  0.181666   \n",
       "\n",
       "   Precision@10  Recall@10   nDCG@10  \n",
       "0      0.034316   0.343157  0.209103  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings_tfidf_test = rankings_tdidf_final[n_train:]\n",
    "evaluate(y_true, rankings_tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395edf7b",
   "metadata": {},
   "source": [
    "De la misma manera, se evaluan los embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7cadbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision@1</th>\n",
       "      <th>Recall@1</th>\n",
       "      <th>nDCG@1</th>\n",
       "      <th>Precision@5</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>nDCG@5</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174945</td>\n",
       "      <td>0.174945</td>\n",
       "      <td>0.174945</td>\n",
       "      <td>0.069731</td>\n",
       "      <td>0.348654</td>\n",
       "      <td>0.266843</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>0.418628</td>\n",
       "      <td>0.289532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision@1  Recall@1    nDCG@1  Precision@5  Recall@5    nDCG@5  \\\n",
       "0     0.174945  0.174945  0.174945     0.069731  0.348654  0.266843   \n",
       "\n",
       "   Precision@10  Recall@10   nDCG@10  \n",
       "0      0.041863   0.418628  0.289532  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rankings_emb_test = rankings_emb_final[n_train:]\n",
    "evaluate(y_true, rankings_emb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2fba02",
   "metadata": {},
   "source": [
    "### Conclusiones \n",
    "\n",
    "En este trabajo se ha implementado y evaluado un sistema de recuperación de información en español utilizando el dataset Messirve y un subconjunto de Wikipedia. Se han comparado dos enfoques: un modelo léxico basado en TF-IDF y un modelo semántico basado en embeddings.\n",
    "\n",
    "Los resultados obtenidos muestran una superioridad clara del modelo basado en embeddings frente al enfoque TF-IDF en todas las métricas evaluadas. En particular, la Precision@1 pasa de 0.100 en TF-IDF a 0.175 en embeddings, lo que supone un incremento notable en la proporción de consultas cuyo documento correcto aparece en primera posición. Asimismo, el Recall@10 aumenta de 0.343 a 0.419, lo que indica que el modelo semántico recupera el documento relevante dentro del top-10 en un mayor número de casos. De forma coherente, el nDCG@10 también mejora de 0.209 a 0.290, reflejando una mejor ordenación de los resultados.\n",
    "\n",
    "Estos resultados confirman que el modelo de embeddings captura mejor la similitud semántica entre consultas y documentos que el modelo léxico basado en coincidencia de términos. Mientras que TF-IDF depende de coincidencias exactas de palabras, los embeddings permiten generalizar a sinónimos y variaciones, lo que da mucha mayor flexibilidad.\n",
    "\n",
    "Como posibles mejoras, se propone explorar enfoques híbridos que combinen modelos sparse y dense, utilizar modelos de embeddings más avanzados, aplicar técnicas de re-ranking con cross-encoders o usar modelos más complejos y específicos para el idioma espanol como se comentó en este notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
